{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b0d3994",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello LangChain ChatGPT\n"
     ]
    }
   ],
   "source": [
    "print('Hello LangChain ChatGPT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a26a966a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI \n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "# print(OPENAI_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30e65600",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['input'] input_types={} partial_variables={} messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='당신은 개발자입니다.'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})]\n"
     ]
    }
   ],
   "source": [
    "# prompt\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [ (\"system\", \"당신은 개발자입니다.\") , # 모델의 역할 부여. 당산읜 개발자 입니다라는 역할 부여\n",
    "     (\"human\", \"{input}\") ]             # prompt.format(input=\"\")으로 실제값 대체체\n",
    ")\n",
    "print(prompt)\n",
    "\n",
    "# \"LangServe는 무엇인가요? 자세하게 설명해주세요\"라는 메세지가 LLM 모델에 전달\n",
    "prompt_text = prompt.format(input=\"LangServe는 무엇인가요? 자세하게 설명해주세요\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0caddc84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "client=<openai.resources.chat.completions.completions.Completions object at 0x00000220A0D07410> async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x00000220A0D074A0> root_client=<openai.OpenAI object at 0x00000220A0CDA3C0> root_async_client=<openai.AsyncOpenAI object at 0x00000220A0D05D60> model_name='gpt-4o' temperature=0.7 model_kwargs={} openai_api_key=SecretStr('**********')\n"
     ]
    }
   ],
   "source": [
    "# ChatGPT API를 사용하는 ChatOpenAI 인스턴스 생성\n",
    "llm = ChatOpenAI(\n",
    "    # model=\"gpt-3.5-turbo-0125\",\n",
    "    # model=\"gpt-4o-mini\",\n",
    "    model=\"gpt-4o\",         # 모델 이름: gpt-4o\n",
    "    temperature=0.7         # 모델의 응답 다양성을 제어하는 매개변수: temperature(\n",
    "                            #   - 0에 가까울수록: 모델의 응답이 더 예측 가능하고 일관되며 보수적으로 변함\n",
    "                            #                   사실적이거나 정확한 정보를 요구할 때 유용\n",
    "                            #   - 1에 가까울수록: 모델의 응답이 더 다양하고 창의적이며 무작위성 증가\n",
    "                            #                   새로운 아이디어를 얻거나 스토리 생성 등 창의적 작업에 유용                  \n",
    "                            # )\n",
    ")\n",
    "print(llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f88980c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.messages.ai.AIMessage'>\n",
      "content='LangServe는 특정한 서비스나 제품 이름으로 보이지 않으며, 일반적으로 알려진 기술 용어도 아닙니다. \"LangServe\"라는 이름은 특정 회사나 조직에서 개발한 소프트웨어, 서비스, API, 또는 다른 종류의 기술 솔루션일 수 있습니다. 만약 LangServe라는 이름을 가진 특정 제품이나 서비스에 대해 알고 싶다면, 관련 문서나 공식 웹사이트에서 정보를 찾거나 해당 서비스를 제공하는 회사나 조직에 문의하는 것이 가장 정확할 것입니다.\\n\\n일반적으로 기술 분야에서 \"Lang\"라는 접두사는 \"language\"의 약자로 사용될 수 있으며, 이는 프로그래밍 언어, 자연어 처리 또는 다른 형태의 언어와 관련된 기술을 의미할 수 있습니다. \"Serve\"는 서버 또는 서비스와 관련된 기능을 의미할 수 있습니다. 이러한 조합으로 볼 때, LangServe는 언어 처리와 관련된 서버 기반 서비스나 API일 가능성도 있습니다.\\n\\n더 구체적인 정보를 제공해 주시면 보다 정확한 답변을 드릴 수 있을 것입니다.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 221, 'prompt_tokens': 28, 'total_tokens': 249, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_a288987b44', 'id': 'chatcmpl-BglZZwzVqB8cDuwq5szg4IvcCoZGC', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None} id='run--28439f78-b8ba-4818-ae24-24962666561a-0' usage_metadata={'input_tokens': 28, 'output_tokens': 221, 'total_tokens': 249, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n",
      "<class 'str'>\n",
      "응답: LangServe는 특정한 서비스나 제품 이름으로 보이지 않으며, 일반적으로 알려진 기술 용어도 아닙니다. \"LangServe\"라는 이름은 특정 회사나 조직에서 개발한 소프트웨어, 서비스, API, 또는 다른 종류의 기술 솔루션일 수 있습니다. 만약 LangServe라는 이름을 가진 특정 제품이나 서비스에 대해 알고 싶다면, 관련 문서나 공식 웹사이트에서 정보를 찾거나 해당 서비스를 제공하는 회사나 조직에 문의하는 것이 가장 정확할 것입니다.\n",
      "\n",
      "일반적으로 기술 분야에서 \"Lang\"라는 접두사는 \"language\"의 약자로 사용될 수 있으며, 이는 프로그래밍 언어, 자연어 처리 또는 다른 형태의 언어와 관련된 기술을 의미할 수 있습니다. \"Serve\"는 서버 또는 서비스와 관련된 기능을 의미할 수 있습니다. 이러한 조합으로 볼 때, LangServe는 언어 처리와 관련된 서버 기반 서비스나 API일 가능성도 있습니다.\n",
      "\n",
      "더 구체적인 정보를 제공해 주시면 보다 정확한 답변을 드릴 수 있을 것입니다.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    response = llm.invoke(prompt_text)  # ChatOpenAI 인스턴스인 llm.invoke()로 위에 선언한 prompt_text 문자열 질의를 보냄\n",
    "    print(type(response))   # AIMessage 타입\n",
    "    print(response)     # content=''LangServe는 특정한 서비스나 제품 이름으로 보이지 않으며,...': \n",
    "                        #       모델이 실제로 생성한 텍스트 답변\n",
    "                        # additional_kwargs{'refusal'L None}: \n",
    "                        #       응답을 거부했는지 여부 지금은 거부하지 않음\n",
    "                        # response_metadata{: API 호출과 관련된 중요 정보\n",
    "                        #   'token_usage': {                #사용 된 토큰 수      \n",
    "                        #       'completion_tokens': 221,   \n",
    "                        #       'prompt_tokens': 28,\n",
    "                        #       'total_tokens': 249, \n",
    "                        #       'completion_tokens_details': {          #모델이 답변을 생성하는 과정에서 사용된 토큰에 대한 더 세부적인 정보\n",
    "                        #           'accepted_prediction_tokens': 0,    #예측 된 토큰 중 최종적으로 채텍된 토큰 수 \n",
    "                        #           'audio_tokens': 0,                  #오디오 입력이 치리 된 경우 사용되는 토큰 수\n",
    "                        #           'reasoning_tokens': 0               #모델이 추론 과정을 거치며 사용한 토큰 수\n",
    "                        #           'rejected_prediction_tokens': 0     #예측되었으나 어떤 이유로든 거부 된 토큰 수\n",
    "                        #   },\n",
    "                        #   'prompt_tokens_details': {  #프롬프트 처리 고자ㅓㅇ에서 사용 된 토큰에 대한 세부 정보\n",
    "                            #   'audio_tokens': 0,      #프롬프트에 오디오 입력이 있을 경우 사용된느 토큰 수\n",
    "                            #   'cached_tokens': 0      #프롬프트 일부가 이전에 캐신되어 재사용된 경우의 토큰 수\n",
    "                            # },    \n",
    "                            # 'model_name': 'gpt-4o-2024-08-06',    #이 응답을 생성한 정확한 OpenAI 모델 버전\n",
    "                            # system_fingerprint': 'fp_a288987b44', #응답을 생성한 백엔드 시스템의 특정 구성 또는 버전\n",
    "                            # 'id': 'chatcmpl-BglZZwzVqB8cDuwq5szg4IvcCoZGC'    #이 응답을 위한 고유한 API 요청 ID\n",
    "                            # 'service_tier',: 'default'    #현재 사용하고 있는 API 서비스 티어\n",
    "                            # 'finish_reason': 'stop',      #모델이 응답 생성을 중단한 이유\n",
    "                            # 'logprobs': None              #로그확률 약자. 모델이 각 토큰을 생성할 때의 확률 정보보\n",
    "                        # } \n",
    "                        # id='run--28439f78-b8ba-4818-ae24-24962666561a-0'  #LangChain 내부에서 이 특정 실행(run)에 할당된 고유 ID\n",
    "                        # API 호출에서 사용 된 토큰 사용량에 대한 간략한 요약약\n",
    "                        # usage_metadata={'input_tokens': 28, 'output_tokens': 221, 'total_tokens': 249, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n",
    "                        \n",
    "                        \n",
    "    print(type(response.content))\n",
    "    print(\"응답:\", response.content)\n",
    "except Exception as e:\n",
    "    print(f\"오류 발생: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58aca691",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-basic-kGdHTiMZ-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
