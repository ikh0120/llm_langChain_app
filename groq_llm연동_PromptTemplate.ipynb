{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b0d3994",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello LangChain\n"
     ]
    }
   ],
   "source": [
    "print('Hello LangChain')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a26a966a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI \n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "# print(OPENAI_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "30e65600",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['input'] input_types={} partial_variables={} messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='당신은 개발자입니다.'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})]\n"
     ]
    }
   ],
   "source": [
    "# prompt\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [ (\"system\", \"당신은 개발자입니다.\") , \n",
    "     (\"human\", \"{input}\") ]\n",
    ")\n",
    "print(prompt)\n",
    "\n",
    "prompt_text = prompt.format(input=\"LangServe는 무엇인가요? 자세하게 설명해주세요\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0caddc84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "client=<openai.resources.chat.completions.completions.Completions object at 0x00000222B7E7CFB0> async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x00000222B819E840> root_client=<openai.OpenAI object at 0x00000222B7D69700> root_async_client=<openai.AsyncOpenAI object at 0x00000222B7D86A50> model_name='meta-llama/llama-4-scout-17b-16e-instruct' temperature=0.7 model_kwargs={} openai_api_key=SecretStr('**********') openai_api_base='https://api.groq.com/openai/v1'\n"
     ]
    }
   ],
   "source": [
    "# Groq API를 사용하는 ChatOpenAI 인스턴스 생성\n",
    "llm = ChatOpenAI(\n",
    "    #api_key=OPENAI_API_KEY,\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API 엔드포인트\n",
    "    model=\"meta-llama/llama-4-scout-17b-16e-instruct\",\n",
    "    #model=\"mistral-saba-24b\",\n",
    "    temperature=0.7\n",
    ")\n",
    "print(llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f88980c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.messages.ai.AIMessage'>\n",
      "content='LangServe는 LangChain이라는 프레임워크를 기반으로 구축된 오픈 소스 라이브러리입니다. LangChain은 자연어 처리(NLP) 및 인공지능(AI) 모델을 활용하여 애플리케이션을 구축하기 위한 프레임워크입니다. LangServe는 이 LangChain을 사용하여 API 서버를 쉽게 구축할 수 있도록 도와주는 라이브러리입니다.\\n\\nLangServe를 사용하면 LangChain의 기능을 활용하여 자연어 처리 및 AI 모델을 API 서버에 쉽게 통합할 수 있습니다. LangServe는 다음과 같은 기능을 제공합니다.\\n\\n1. **API 서버 구축**: LangServe를 사용하면 LangChain의 기능을 활용하여 API 서버를 쉽게 구축할 수 있습니다. LangServe는 Flask 또는 FastAPI와 같은 웹 프레임워크를 사용하여 API 서버를 구축합니다.\\n\\n2. **LangChain 통합**: LangServe는 LangChain을 사용하여 자연어 처리 및 AI 모델을 API 서버에 통합합니다. 이를 통해 개발자는 LangChain의 다양한 기능을 활용하여 애플리케이션을 구축할 수 있습니다.\\n\\n3. **모델 배포**: LangServe를 사용하면 다양한 AI 모델을 배포할 수 있습니다. 예를 들어, 언어 모델, 분류 모델, 객체 탐지 모델 등을 배포할 수 있습니다.\\n\\n4. **API 엔드포인트 관리**: LangServe는 API 엔드포인트를 쉽게 관리할 수 있도록 도와줍니다. 개발자는 API 엔드포인트를 정의하고, 요청을 처리하며, 응답을 반환할 수 있습니다.\\n\\n5. **인증 및 권한 관리**: LangServe는 인증 및 권한 관리를 지원합니다. 개발자는 API 서버에 인증 및 권한 관리를 쉽게 통합할 수 있습니다.\\n\\nLangServe의 주요 특징은 다음과 같습니다.\\n\\n* **오픈 소스**: LangServe는 오픈 소스 라이브러리입니다. 누구나 무료로 사용할 수 있으며, 소스코드를 수정하고 재배포할 수 있습니다.\\n* **확장성**: LangServe는 확장성이 뛰어납니다. 개발자는 LangServe를 사용하여 다양한 애플리케이션을 구축할 수 있습니다.\\n* **쉬운 사용**: LangServe는 사용하기 쉽습니다. 개발자는 LangServe를 사용하여 빠르게 API 서버를 구축할 수 있습니다.\\n\\nLangServe는 다음과 같은 경우에 유용합니다.\\n\\n* **자연어 처리 애플리케이션**: LangServe는 자연어 처리 애플리케이션을 구축하는 데 유용합니다. 예를 들어, 챗봇, 언어 번역, 텍스트 요약 등을 구축할 수 있습니다.\\n* **AI 모델 배포**: LangServe는 AI 모델을 배포하는 데 유용합니다. 예를 들어, 이미지 분류, 객체 탐지, 음성 인식 등을 배포할 수 있습니다.\\n\\n결론적으로, LangServe는 LangChain을 기반으로 구축된 오픈 소스 라이브러리입니다. LangServe를 사용하면 자연어 처리 및 AI 모델을 API 서버에 쉽게 통합할 수 있습니다. LangServe는 확장성이 뛰어나고 사용하기 쉬우며, 다양한 애플리케이션을 구축하는 데 유용합니다.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 574, 'prompt_tokens': 30, 'total_tokens': 604, 'completion_tokens_details': None, 'prompt_tokens_details': None, 'queue_time': 0.349094824, 'prompt_time': 0.004913473, 'completion_time': 1.391834753, 'total_time': 1.396748226}, 'model_name': 'meta-llama/llama-4-scout-17b-16e-instruct', 'system_fingerprint': 'fp_79da0e0073', 'id': 'chatcmpl-045782a1-e819-43d5-b70a-fffbf2afa9ae', 'service_tier': None, 'finish_reason': 'stop', 'logprobs': None} id='run--662240f2-b3b7-443b-a2f3-1c7fecb44493-0' usage_metadata={'input_tokens': 30, 'output_tokens': 574, 'total_tokens': 604, 'input_token_details': {}, 'output_token_details': {}}\n",
      "응답: LangServe는 LangChain이라는 프레임워크를 기반으로 구축된 오픈 소스 라이브러리입니다. LangChain은 자연어 처리(NLP) 및 인공지능(AI) 모델을 활용하여 애플리케이션을 구축하기 위한 프레임워크입니다. LangServe는 이 LangChain을 사용하여 API 서버를 쉽게 구축할 수 있도록 도와주는 라이브러리입니다.\n",
      "\n",
      "LangServe를 사용하면 LangChain의 기능을 활용하여 자연어 처리 및 AI 모델을 API 서버에 쉽게 통합할 수 있습니다. LangServe는 다음과 같은 기능을 제공합니다.\n",
      "\n",
      "1. **API 서버 구축**: LangServe를 사용하면 LangChain의 기능을 활용하여 API 서버를 쉽게 구축할 수 있습니다. LangServe는 Flask 또는 FastAPI와 같은 웹 프레임워크를 사용하여 API 서버를 구축합니다.\n",
      "\n",
      "2. **LangChain 통합**: LangServe는 LangChain을 사용하여 자연어 처리 및 AI 모델을 API 서버에 통합합니다. 이를 통해 개발자는 LangChain의 다양한 기능을 활용하여 애플리케이션을 구축할 수 있습니다.\n",
      "\n",
      "3. **모델 배포**: LangServe를 사용하면 다양한 AI 모델을 배포할 수 있습니다. 예를 들어, 언어 모델, 분류 모델, 객체 탐지 모델 등을 배포할 수 있습니다.\n",
      "\n",
      "4. **API 엔드포인트 관리**: LangServe는 API 엔드포인트를 쉽게 관리할 수 있도록 도와줍니다. 개발자는 API 엔드포인트를 정의하고, 요청을 처리하며, 응답을 반환할 수 있습니다.\n",
      "\n",
      "5. **인증 및 권한 관리**: LangServe는 인증 및 권한 관리를 지원합니다. 개발자는 API 서버에 인증 및 권한 관리를 쉽게 통합할 수 있습니다.\n",
      "\n",
      "LangServe의 주요 특징은 다음과 같습니다.\n",
      "\n",
      "* **오픈 소스**: LangServe는 오픈 소스 라이브러리입니다. 누구나 무료로 사용할 수 있으며, 소스코드를 수정하고 재배포할 수 있습니다.\n",
      "* **확장성**: LangServe는 확장성이 뛰어납니다. 개발자는 LangServe를 사용하여 다양한 애플리케이션을 구축할 수 있습니다.\n",
      "* **쉬운 사용**: LangServe는 사용하기 쉽습니다. 개발자는 LangServe를 사용하여 빠르게 API 서버를 구축할 수 있습니다.\n",
      "\n",
      "LangServe는 다음과 같은 경우에 유용합니다.\n",
      "\n",
      "* **자연어 처리 애플리케이션**: LangServe는 자연어 처리 애플리케이션을 구축하는 데 유용합니다. 예를 들어, 챗봇, 언어 번역, 텍스트 요약 등을 구축할 수 있습니다.\n",
      "* **AI 모델 배포**: LangServe는 AI 모델을 배포하는 데 유용합니다. 예를 들어, 이미지 분류, 객체 탐지, 음성 인식 등을 배포할 수 있습니다.\n",
      "\n",
      "결론적으로, LangServe는 LangChain을 기반으로 구축된 오픈 소스 라이브러리입니다. LangServe를 사용하면 자연어 처리 및 AI 모델을 API 서버에 쉽게 통합할 수 있습니다. LangServe는 확장성이 뛰어나고 사용하기 쉬우며, 다양한 애플리케이션을 구축하는 데 유용합니다.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    response = llm.invoke(prompt_text)\n",
    "    print(type(response))\n",
    "    print(response)\n",
    "    print(\"응답:\", response.content)\n",
    "except Exception as e:\n",
    "    print(f\"오류 발생: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e10ec05b",
   "metadata": {},
   "source": [
    "### LCEL \n",
    "* Prompt + LLM을 Chain으로 연결하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "58aca691",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='\\n    You are an expert in AI Expert. Answer the question. \\n    <Question>: {input}에 대해 쉽게 설명해주세요.\")\\n    ')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "prompt = PromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    You are an expert in AI Expert. Answer the question. \n",
    "    <Question>: {input}에 대해 쉽게 설명해주세요.\")\n",
    "    \"\"\")                                     \n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "724baab8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.runnables.base.RunnableSequence'>\n"
     ]
    }
   ],
   "source": [
    "# chain 연결 (LCEL)\n",
    "chain = prompt | llm\n",
    "print(type(chain))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54ea2af5",
   "metadata": {},
   "source": [
    "### LCEL \n",
    "* Prompt + LLM + outputParser 를 Chain으로 연결하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b3705cdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.runnables.base.RunnableSequence'>\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# chain 연결 (LCEL)\n",
    "output_parser = StrOutputParser()\n",
    "chain2 = prompt | llm | output_parser\n",
    "print(type(chain2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7bbfda0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.messages.ai.AIMessage'>\n",
      "인공지능 모델의 학습 원리는 사람의 뇌가 학습하는 방식과 유사합니다. 컴퓨터에大量的 데이터를 제공하고, 데이터를 분석하여 패턴을 찾고, 패턴을 기반으로 예측이나 판단을 내리는 모델을 만드는 것입니다.\n",
      "\n",
      "구체적으로 설명하면, 인공지능 모델의 학습 과정은 다음과 같습니다:\n",
      "\n",
      "1. **데이터 수집**: 인공지능 모델을 학습시키기 위해大量的 데이터를 수집합니다. 이 데이터는 문제에 따라 다르지만, 이미지, 텍스트, 오디오 등 다양한 형태일 수 있습니다.\n",
      "2. **데이터 전처리**: 수집한 데이터를 분석에 적합한 형태로 변환합니다. 예를 들어, 이미지 데이터를 픽셀 값으로 변환하거나, 텍스트 데이터를 단어 또는 문장으로 분리하는 작업 등이 있습니다.\n",
      "3. **모델 정의**: 인공지능 모델을 정의합니다. 모델은 데이터로부터 패턴을 학습하고, 예측이나 판단을 내리는 알고리즘입니다. 예를 들어, 신경망, 결정 트리, 선형 회귀 등이 있습니다.\n",
      "4. **학습**: 모델에 데이터를 제공하고, 모델이 데이터를 분석하여 패턴을 학습하도록 합니다. 이 과정에서 모델은 데이터를 통해 파라미터를 조정하고, 최적의 모델을 만듭니다.\n",
      "5. **평가**: 학습된 모델의 성능을 평가합니다. 이를 통해 모델의 정확도, 정밀도, 재현율 등을 측정하고, 모델의 성능을 개선할 수 있습니다.\n",
      "\n",
      "예를 들어, 이미지 분류 인공지능 모델을 학습시키는 경우를 생각해 봅시다. \n",
      "\n",
      "* 데이터 수집: 인터넷에서 고양이, 개, 자동차 등의 이미지 데이터를 수집합니다.\n",
      "* 데이터 전처리: 이미지 데이터를 픽셀 값으로 변환하고, 레이블링(고양이, 개, 자동차 등)을 합니다.\n",
      "* 모델 정의: 신경망 모델을 정의하고, Conv2D, MaxPooling2D, Flatten 등의 레이어를 쌓습니다.\n",
      "* 학습: 모델에 이미지 데이터를 제공하고, 모델이 이미지를 분석하여 고양이, 개, 자동차 등을 분류하도록 학습합니다.\n",
      "* 평가: 학습된 모델의 성능을 평가하여, 정확도, 정밀도, 재현율 등을 측정합니다.\n",
      "\n",
      "이렇게 인공지능 모델은 데이터를 통해 학습하고, 패턴을 찾아내어 예측이나 판단을 내리는 것입니다.\n"
     ]
    }
   ],
   "source": [
    "# chain 호출\n",
    "try:\n",
    "    result = chain.invoke({\"input\": \"인공지능 모델의 학습 원리\"})\n",
    "    print(type(result))\n",
    "    print(result.content)\n",
    "except Exception as e:\n",
    "    print(f\"오류 발생: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cc7cde83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "LangChain은 인공지능(AI) 기술을 기반으로 하는 다양한 제품을 제공하는 회사입니다. LangChain의 주요 제품은 다음과 같습니다.\n",
      "\n",
      "1. **LangChain**: 랭체인 플랫폼은 개발자가 언어 모델을 쉽게 구축, 통합 및 배포할 수 있도록 지원하는 프레임워크입니다.\n",
      "\n",
      "2. **LangChain API**: 랭체인 API는 언어 모델을 기반으로 하는 다양한 기능을 제공하는 API입니다. 이 API를 통해 개발자는 랭체인의 언어 모델을 자신의 애플리케이션에 쉽게 통합할 수 있습니다.\n",
      "\n",
      "3. **LangChain Apps**: 랭체인 앱은 랭체인 플랫폼을 기반으로 구축된 다양한 애플리케이션입니다. 이 앱들은 언어 모델을 활용하여 자연어 처리, 대화형 인터페이스, 콘텐츠 생성 등 다양한 기능을 제공합니다.\n",
      "\n",
      "LangChain은 언어 모델을 기반으로 하는 다양한 제품을 제공함으로써, 개발자가 보다 쉽게 AI 기술을 활용할 수 있도록 지원하고 있습니다.\n"
     ]
    }
   ],
   "source": [
    "# chain 호출 \n",
    "try:\n",
    "    result = chain2.invoke({\"input\": \"LangChain의 Products(제품)는 어떤 것들이 있나요?\"})\n",
    "    print(type(result))\n",
    "    print(result)\n",
    "except Exception as e:\n",
    "    print(f\"오류 발생: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e71ce16",
   "metadata": {},
   "source": [
    "### Runnable의 stream() 메서드 호출\n",
    "* invoke()는 한 번에 처리해서 반환\n",
    "* stream()은 순차적으로 부분적인 결과(토큰)들을 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "18ddb1cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "인공지능 모델의 학습 원리를 쉽게 설명해 드리겠습니다.\n",
      "\n",
      "인공지능 모델의 학습 원리는 크게 다음과 같은 과정으로 이루어집니다:\n",
      "\n",
      "1. **데이터 수집**: 인공지능 모델을 학습시키기 위해서는 많은 양의 데이터가 필요합니다. 이 데이터는 문제에 대한 답이 포함된 형태여야 합니다. 예를 들어, 고양이와 강아지의 사진을 분류하는 모델을 만든다고 가정해 봅시다. 이 경우, 고양이와 강아지의 사진 데이터와 그에 대한 라벨(고양이 또는 강아지)이 필요합니다.\n",
      "\n",
      "2. **데이터 전처리**: 수집된 데이터는 모델에 사용하기 전에 전처리 과정을 거칩니다. 이 과정에서는 데이터의 품질을 높이고, 일관성을 맞추며, 모델이 학습하기 좋은 형태로 변환하는 작업을 수행합니다.\n",
      "\n",
      "3. **모델 선택**: 적합한 인공지능 모델을 선택합니다. 모델의 종류에는 신경망, 결정 트리, 서포트 벡터 머신 등 여러 가지가 있으며, 문제의 성격에 따라 적합한 모델을 선택합니다.\n",
      "\n",
      "4. **모델 학습**: 선택한 모델에 전처리된 데이터를 입력하여 모델을 학습시킵니다. 이 과정에서는 모델이 데이터로부터 패턴을 학습하고, 주어진 문제에 대한 답을 예측할 수 있도록 합니다. 모델은 예측 결과와 실제 답 사이의 오류를 계산하고, 이 오류를 최소화하는 방향으로 스스로를 업데이트합니다.\n",
      "\n",
      "5. **모델 평가**: 학습이 완료된 모델을 평가합니다. 이를 통해 모델의 성능을 측정하고, 필요에 따라 모델의 하이퍼파рамет러를 조정하거나 학습 데이터를 추가하는 등의 작업을 수행합니다.\n",
      "\n",
      "6. **모델 배포**: 평가를 통해 만족할 만한 성능을 보이는 모델을 배포합니다. 이 모델은 새로운 입력 데이터에 대해 예측을 수행하고, 실제 문제 해결에 사용됩니다.\n",
      "\n",
      "예를 들어, 고양이와 강아지의 사진을 분류하는 모델을 만든다고 가정해 봅시다. \n",
      "\n",
      "- **데이터 수집**: 고양이와 강아지의 사진 여러 장을 수집하고, 각각의 사진에 '고양이' 또는 '강아지'라는 라벨을 붙입니다.\n",
      "- **데이터 전처리**: 사진의 크기를 일관되게 조정하거나, 픽셀 값을 정규화하는 등의 작업을 수행합니다.\n",
      "- **모델 선택**: 이미지 분류에 적합한 신경망 모델을 선택합니다.\n",
      "- **모델 학습**: 신경망 모델에 고양이와 강아지의 사진 데이터를 입력하고, 라벨을 통해 모델이 고양이와 강아지를 구분하도록 학습시킵니다.\n",
      "- **모델 평가**: 학습된 모델을 평가하여 고양이와 강아지를 얼마나 정확하게 분류하는지 확인합니다.\n",
      "- **모델 배포**: 평가 결과 만족할 만한 성능을 보이면, 실제 고양이와 강아지의 사진을 분류하는 작업에 모델을 배포합니다.\n",
      "\n",
      "이처럼 인공지능 모델은 주어진 데이터를 통해 스스로 학습하고, 새로운 데이터에 대해 예측을 수행할 수 있습니다."
     ]
    }
   ],
   "source": [
    "# chain 호출 \n",
    "try:\n",
    "    answer = chain2.stream({\"input\": \"인공지능 모델의 학습 원리를 자세히 설명해줘\"}) # 스트리밍 출력을 위한 요청\n",
    "    # print(answer) # 스트리밍 출력\n",
    "    for token in answer:\n",
    "        # 스트림에서 받은 데이터의 내용을 출력합니다. 줄바꿈 없이 이어서 출력하고, 버퍼를 즉시 비웁니다.\n",
    "        print(token, end=\"\", flush=True)\n",
    "except Exception as e:\n",
    "    print(f\"오류 발생: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b407355",
   "metadata": {},
   "source": [
    "### Multi Chain\n",
    "* 첫번째 Chain 출력이 두번째 Chain의 입력이 된다\n",
    "* 두개의 Chain과 Prompt + OutputParser 를 LCEL로 연결하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "849ae816",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# Step 1: 사용자가 입력한 장르에 따라 영화 추천\n",
    "prompt1 = ChatPromptTemplate.from_template(\"{genre} 장르에서 추천할 만한 영화를 한 편 알려주세요.\")\n",
    "\n",
    "# Step 2: 추천된 영화의 줄거리를 요약\n",
    "prompt2 = ChatPromptTemplate.from_template(\"{movie} 추전한 영화의 제목을 먼저 알려주시고, 줄을 바꾸어서 영화의 줄거리를 3문장으로 요약해 주세요.\")\n",
    "\n",
    "# OpenAI 모델 사용\n",
    "llm = ChatOpenAI(\n",
    "    #api_key=OPENAI_API_KEY,\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API 엔드포인트\n",
    "    model=\"meta-llama/llama-4-scout-17b-16e-instruct\",\n",
    "    #model=\"mistral-saba-24b\",\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "# 체인 1: 영화 추천 (입력: 장르 → 출력: 영화 제목)\n",
    "chain1 = prompt1 | llm | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5dd7619d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## 존 윅\n",
      "\n",
      "전직 킬러 존 윅은 은퇴 후 평화로운 삶을 살고 있었지만, 어떤 범죄 조직의 일원에게 차를 훔치고, 집에서 개를 죽이는 등 여러 피해를 입습니다. \n",
      "\n",
      "이에 존 윅은 다시 킬러로 돌아가 이 조직과 그 배후에 있는 고위급 인사 '비긴스(Viggo Tarasov)'를 상대로 복수를 시작합니다. \n",
      "\n",
      "복수를 주제로 한 스토리가 깔끔하게 전개되며, 복잡하지 않은 플롯으로 쉽게 몰입할 수 있습니다.\n"
     ]
    }
   ],
   "source": [
    "# 체인 2: 줄거리 요약 (입력: 영화 제목 → 출력: 줄거리)\n",
    "try:\n",
    "    chain2 = (\n",
    "        {\"movie\": chain1}  # chain1의 출력을 movie 입력 변수로 전달\n",
    "        | prompt2\n",
    "        | llm\n",
    "        | StrOutputParser()\n",
    "    )\n",
    "\n",
    "    # 실행: \"SF\" 장르의 영화 추천 및 줄거리 요약\n",
    "    response = chain2.invoke({\"genre\": \"액션\"})\n",
    "    print(response)  \n",
    "except Exception as e:\n",
    "    print(f\"오류 발생: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eef43e9",
   "metadata": {},
   "source": [
    "### Prompt Template 여러 개 연결하기    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c6302046",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatGPT 모델의 학습 원리는 다음과 같습니다.\n",
      "\n",
      "ChatGPT는 대규모의 텍스트 데이터를 기반으로 하는 언어 모델입니다. 이 모델은 주어진 문맥에 따라 다음에 올 단어를 예측하도록 학습하며, 이를 통해 자연스러운 대화가 가능하도록 설계되었습니다. 학습 과정에서 ChatGPT는 많은 양의 텍스트 데이터를 분석하고 패턴을 학습하여, 다양한 주제와 상황에 대한 응답을 생성할 수 있습니다.\n",
      "\n",
      "ChatGPT 모델의 장점은 다음과 같습니다.\n",
      "\n",
      "* 자연스러운 대화가 가능합니다.\n",
      "* 다양한 주제와 상황에 대한 응답을 생성할 수 있습니다.\n",
      "* 대규모의 텍스트 데이터를 기반으로 학습하여 높은 정확도를 제공합니다.\n",
      "* 지속적인 학습과 업데이트를 통해 성능이 개선됩니다.\n",
      "\n",
      "ChatGPT 모델과 비슷한 AI 모델은 다음과 있습니다.\n",
      "\n",
      "* LLaMA\n",
      "* PaLM\n",
      "* BERT\n",
      "* RoBERTa\n",
      "\n",
      "특히 LLaMA와 PaLM은 Meta와 Google에서 개발한 대규모 언어 모델로, ChatGPT와 유사한 성능을 제공합니다. BERT와 RoBERTa는 구글에서 개발한 언어 모델로, 자연어 처리 작업에서 높은 성능을 제공합니다.\n"
     ]
    }
   ],
   "source": [
    "template_text = \"{model_name} 모델의 학습 원리를 {count} 문장으로 요약해서 한국어로 답변해 주세요.\"\n",
    "\n",
    "# PromptTemplate 인스턴스를 생성\n",
    "prompt_template = PromptTemplate.from_template(template_text)\n",
    "\n",
    "# 템플릿에 값을 채워서 프롬프트를 완성\n",
    "filled_prompt = prompt_template.format(model_name=\"ChatGPT\", count=3)\n",
    "\n",
    "# 문자열 템플릿 결합 (PromptTemplate + PromptTemplate + 문자열)\n",
    "combined_prompt = (\n",
    "              prompt_template\n",
    "              + PromptTemplate.from_template(\"\\n\\n 그리고 {model_name} 모델의 장점을 요약 정리해 주세요\")\n",
    "              + \"\\n\\n {model_name} 모델과 비슷한 AI 모델은 어떤 것이 있나요? 모델명은 {language}로 답변해 주세요.\"\n",
    ")\n",
    "combined_prompt.format(model_name=\"ChatGPT\", count=3, language=\"영어\")\n",
    "\n",
    "# OpenAI 모델 사용\n",
    "llm = ChatOpenAI(\n",
    "    #api_key=OPENAI_API_KEY,\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API 엔드포인트\n",
    "    model=\"meta-llama/llama-4-scout-17b-16e-instruct\",\n",
    "    #model=\"mistral-saba-24b\",\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "chain = combined_prompt | llm | StrOutputParser()\n",
    "response = chain.invoke({\"model_name\":\"ChatGPT\", \"count\":3, \"language\":\"영어\"})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9f536075",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['GPT-4 모델의 학습 원리를 2 문장으로 한국어로 답변해 주세요.', 'Gemma 모델의 학습 원리를 3 문장으로 한국어로 답변해 주세요.', 'llama-4 모델의 학습 원리를 4 문장으로 한국어로 답변해 주세요.']\n"
     ]
    }
   ],
   "source": [
    "template_text = \"{model_name} 모델의 학습 원리를 {count} 문장으로 한국어로 답변해 주세요.\"\n",
    "\n",
    "# PromptTemplate 인스턴스를 생성\n",
    "prompt_template = PromptTemplate.from_template(template_text)\n",
    "\n",
    "questions = [\n",
    "    {\"model_name\": \"GPT-4\", \"count\": 2},\n",
    "    {\"model_name\": \"Gemma\", \"count\": 3},\n",
    "    {\"model_name\": \"llama-4\", \"count\": 4},\n",
    "]\n",
    "\n",
    "# 여러 개의 프롬프트를 미리 생성\n",
    "formatted_prompts = [prompt_template.format(**q) for q in questions]\n",
    "print(formatted_prompts)  # 미리 생성된 질문 목록 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "402019c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT-4 모델은 대규모의 텍스트 데이터를 학습하여 언어 패턴과 구조를 이해하고, 이를 바탕으로 자연어 처리 작업을 수행하는 인공지능 모델입니다. GPT-4는 이전 모델인 GPT-3와 마찬가지로 트랜스포머 아키텍처를 기반으로 하며, 대규모 데이터셋을 학습하여 언어 모델링 작업을 수행합니다.\n",
      "Gemma는 컴퓨터가 자연어 작업을 더 잘 수행하도록 돕는 인공지능(AI) 모델입니다. 텍스트 데이터를 학습하여 언어의 패턴과 구조를 이해하고, 이를 기반으로 질문에 답하거나 문장을 생성하는 등의 작업을 수행합니다. Gemma는 대규모의 텍스트 데이터를 학습하여 언어에 대한 깊은 이해를 얻고, 이를 통해 다양한 자연어 처리 작업에 활용될 수 있습니다.\n",
      "llama-4 모델은 메타에서 개발한 대규모 언어 모델입니다. 이 모델은 방대한 양의 텍스트 데이터를 기반으로 학습되며, 이를 통해 자연어 처리 능력을 습득합니다. 학습 과정에서 모델은 입력된 텍스트의 패턴과 구조를 분석하고, 이를 바탕으로 다음에 올 수 있는 단어나 문장을 예측합니다. 이러한 과정을 반복하면서 모델은 언어에 대한 이해와 생성 능력을 향상시키게 됩니다.\n"
     ]
    }
   ],
   "source": [
    "# OpenAI 모델 사용\n",
    "llm = ChatOpenAI(\n",
    "    #api_key=OPENAI_API_KEY,\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API 엔드포인트\n",
    "    model=\"meta-llama/llama-4-scout-17b-16e-instruct\",\n",
    "    #model=\"mistral-saba-24b\",\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "for prompt in formatted_prompts:\n",
    "    response = llm.invoke(prompt) #AIMessage\n",
    "    print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6eba059",
   "metadata": {},
   "source": [
    "ChatPromptTemplate\n",
    "* SystemMessagePromptTemplate, HumanMessagePromptTemplate, AIMessagePromptTemplate 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0a71cced",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "\n",
      "## Definition \n",
      "\n",
      "딥러닝은 인공신경망을 사용하여 데이터를 분석하고 패턴을 찾는 머신러닝의 한 분야입니다. 딥러닝은 데이터의 복잡한 패턴을 학습하고 높은 수준의 추상화를 달성할 수 있습니다.\n",
      "\n",
      "## Key Features \n",
      "\n",
      "* **인공신경망**: 딥러닝은 인공신경망을 사용하여 데이터를 처리합니다. 인공신경망은 인간의 뇌를 모방한 구조로, 여러 층의 노드와 연결로 구성됩니다.\n",
      "* **다중 층**: 딥러닝은 다중 층의 인공신경망을 사용하여 데이터를 처리합니다. 각 층은 데이터를 변환하고 특징을 추출합니다.\n",
      "* **학습**: 딛러닝은 데이터를 학습하여 패턴을 찾습니다. 학습 과정에서는 인공신경망의 가중치를 조정하여 오류를 최소화합니다.\n",
      "\n",
      "## Applications \n",
      "\n",
      "* **이미지 인식**: 딥러닝은 이미지 인식 분야에서 널리 사용됩니다. 예를 들어, 얼굴 인식, 객체 인식, 이미지 분류 등이 있습니다.\n",
      "* **자연어 처리**: 딥러닝은 자연어 처리 분야에서 사용됩니다. 예를 들어, 언어 번역, 감정 분석, 텍스트 분류 등이 있습니다.\n",
      "* **음성 인식**: 딥러닝은 음성 인식 분야에서 사용됩니다. 예를 들어, 음성 번역, 음성 인식 등이 있습니다.\n",
      "\n",
      "## Examples \n",
      "\n",
      "* **Self-Driving Cars**: 딥러닝은 자율 주행 자동차에서 사용됩니다. 예를 들어, 카메라와 센서를 사용하여 도로를 인식하고 주행합니다.\n",
      "* **Virtual Assistants**: 딥러닝은 가상 비서에서 사용됩니다. 예를 들어, 음성 인식과 자연어 처리를 사용하여 사용자의 요청을 처리합니다.\n",
      "\n",
      "## Conclusion \n",
      "\n",
      "딥러닝은 데이터 분석과 패턴 인식을 위한 강력한 도구입니다. 다양한 분야에서 응용되고 있으며, 지속적인 연구와 개발이 이루어지고 있습니다.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import (\n",
    "    ChatPromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    "    AIMessagePromptTemplate\n",
    ")\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# 개별 메시지 템플릿 정의\n",
    "system_message = SystemMessagePromptTemplate.from_template(\n",
    "    \"너는 {topic} 전문가야. 명확하고 자세히 설명해\"\n",
    ")\n",
    "user_message = HumanMessagePromptTemplate.from_template(\n",
    "    \"{question}\"\n",
    ")\n",
    "ai_message = AIMessagePromptTemplate.from_template(\n",
    "    \"This is an example answer about {topic}.\"\n",
    ")\n",
    "\n",
    "# ChatPromptTemplate로 메시지들을 묶기\n",
    "chat_prompt = ChatPromptTemplate.from_messages([\n",
    "    system_message,\n",
    "    user_message,\n",
    "    ai_message\n",
    "])\n",
    "\n",
    "# 메시지 생성\n",
    "messages = chat_prompt.format_messages(topic=\"AI\", question=\"딥러닝이 뭐야?\")\n",
    "\n",
    "# LLM 호출\n",
    "llm = ChatOpenAI(\n",
    "    #api_key=OPENAI_API_KEY,\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API 엔드포인트\n",
    "    model=\"meta-llama/llama-4-scout-17b-16e-instruct\",\n",
    "    temperature=0.7\n",
    ")\n",
    "response = llm.invoke(messages)\n",
    "\n",
    "# 결과 출력\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a729ff4",
   "metadata": {},
   "source": [
    "### FewShotPromptTemplate\n",
    "* 예시 제공 프롬프트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3d501933",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### 태양계의 행성\n",
      "1. **수성**: 태양과 가장 가까운 행성으로, 표면이 매우 뜨겁고 춥습니다.\n",
      "2. **금성**: 두꺼운 대기로 인해 극심한 온실 효과가 있습니다.\n",
      "3. **지구**: 생명체가 살고 있는 유일한 행성입니다.\n",
      "4. **화성**: 붉은색으로 유명하며, 과거에는 물이 있었다고 추정됩니다.\n",
      "5. **목성**: 태양계에서 가장 큰 행성으로, 주로 가스로 구성되어 있습니다.\n",
      "6. **토성**: 아름다운 고리를 가지고 있습니다.\n",
      "7. **천왕성**: 자전축이 기울어져 있어 극단적인 계절 변화를 겪습니다.\n",
      "8. **해왕성**: 태양계에서 가장 먼 행성으로, 강한 바람이 불고 있습니다.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, FewShotChatMessagePromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "examples = [\n",
    "    {\n",
    "        \"input\": \"뉴턴의 운동 법칙을 요약해 주세요.\",\n",
    "        \"output\": \"\"\"### 뉴턴의 운동 법칙\n",
    "1. **관성의 법칙**: 힘이 작용하지 않으면 물체는 계속 같은 상태를 유지합니다.\n",
    "2. **가속도의 법칙**: 물체에 힘이 작용하면, 힘과 질량에 따라 가속도가 결정됩니다.\n",
    "3. **작용-반작용 법칙**: 모든 힘에는 크기가 같고 방향이 반대인 힘이 작용합니다.\"\"\"\n",
    "    },\n",
    "    {\n",
    "        \"input\": \"지구의 대기 구성 요소를 알려주세요.\",\n",
    "        \"output\": \"\"\"### 지구 대기의 구성\n",
    "- **질소 (78%)**: 대기의 대부분을 차지합니다.\n",
    "- **산소 (21%)**: 생명체가 호흡하는 데 필요합니다.\n",
    "- **아르곤 (0.93%)**: 반응성이 낮은 기체입니다.\n",
    "- **이산화탄소 (0.04%)**: 광합성 및 온실 효과에 중요한 역할을 합니다.\"\"\"\n",
    "    }\n",
    "]\n",
    "\n",
    "# 예제 프롬프트 템플릿\n",
    "example_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"human\", \"{input}\"),\n",
    "        (\"ai\", \"{output}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# FewShotChatMessagePromptTemplate 적용\n",
    "few_shot_prompt = FewShotChatMessagePromptTemplate(\n",
    "    example_prompt=example_prompt,\n",
    "    examples=examples,\n",
    ")\n",
    "\n",
    "# 최종 프롬프트 구성\n",
    "final_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"당신은 초등학생도 이해할 수 있도록 쉽게 설명하는 과학 교육자입니다.\"),\n",
    "        few_shot_prompt,\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# 모델 생성 및 체인 구성\n",
    "#model = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.0)\n",
    "model = ChatOpenAI(\n",
    "    #api_key=OPENAI_API_KEY,\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API 엔드포인트\n",
    "    model=\"meta-llama/llama-4-scout-17b-16e-instruct\",\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "chain = final_prompt | model\n",
    "\n",
    "# 테스트 실행\n",
    "result = chain.invoke({\"input\": \"태양계의 행성들을 간략히 정리해 주세요.\"})\n",
    "#result = chain.invoke({\"input\": \"양자 얽힘이 무엇인가요?\"})\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ff157ea",
   "metadata": {},
   "source": [
    "### PartialPromptTemplate\n",
    "* 프롬프트 입력값에 동적인 메서드 호출이나 외부 API를 호출한 동적인 값을 대입 가능함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6b4024a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "현재 계절: 겨울\n",
      "🔹 프롬프트: input_variables=['season'] input_types={} partial_variables={} messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['season'], input_types={}, partial_variables={}, template='{season}에 주로 발생하는 대표적인 지구과학 현상 3가지를 알려주세요. 각 현상에 대해 간단한 설명을 포함해주세요.'), additional_kwargs={})]\n",
      "🔹 모델 응답: 겨울에 발생하는 자연 현상: \n",
      " 1.  **오로라**: 오로라는 태양에서 방출된 하전 입자가 지구 자기장에 의해 극지방으로 끌려가면서 대기와의 충돌로 인해 발생합니다. 오로라는 북극에서는 녹색, 북극에서는 붉은 색으로 나타나며, 밤하늘을 수놓은 듯한 아름다운 광경을 연출합니다.\n",
      "\n",
      "2.  **성층권 극소용돌이**: 성층권 극소용돌이는 극지방의 성층권에서 발생하는 대규모의 회전 현상입니다. 이 현상은 극지방의 찬 공기가 하강하고 중위도의 따뜻한 공기가 상승하는 것을 막아주어, 극지방의 극한 날씨를 유지하는 데 중요한 역할을 합니다.\n",
      "\n",
      "3.  **빙하 형성**: 빙하는 극지방이나 높은 산에서 발생하는 자연 현상으로, 눈이 쌓이고 압축되어 얼음 덩어리가 형성되는 것을 말합니다. 빙하는 기후 변화에 민감하게 반응하며, 지구의 평균 기온 상승으로 인해 빙하의 크기와 두께가 감소하고 있습니다.\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# 계절을 결정하는 함수 (남반구/북반구 고려)\n",
    "def get_current_season(hemisphere=\"north\"):\n",
    "    month = datetime.now().month\n",
    "    \n",
    "    if hemisphere == \"north\":  # 북반구 (기본값)\n",
    "        if 3 <= month <= 5:\n",
    "            return \"봄\"\n",
    "        elif 6 <= month <= 8:\n",
    "            return \"여름\"\n",
    "        elif 9 <= month <= 11:\n",
    "            return \"가을\"\n",
    "        else:\n",
    "            return \"겨울\"\n",
    "    else:  # 남반구 (계절 반대)\n",
    "        if 3 <= month <= 5:\n",
    "            return \"가을\"\n",
    "        elif 6 <= month <= 8:\n",
    "            return \"겨울\"\n",
    "        elif 9 <= month <= 11:\n",
    "            return \"봄\"\n",
    "        else:\n",
    "            return \"여름\"\n",
    "\n",
    "# 프롬프트 템플릿 정의 (부분 변수 적용)\n",
    "\n",
    "# prompt = PromptTemplate(\n",
    "#     template=\"{season}에 일어나는 대표적인 지구과학 현상은 {phenomenon}입니다.\",\n",
    "#     input_variables=[\"phenomenon\"],  # 사용자 입력 필요\n",
    "#     partial_variables={\"season\": get_current_season(\"south\")}  # 동적으로 계절 값 할당\n",
    "# )\n",
    "\n",
    "season = get_current_season(\"south\")\n",
    "print(f\"현재 계절: {season}\")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\n",
    "    \"{season}에 주로 발생하는 대표적인 지구과학 현상 3가지를 알려주세요. \"\n",
    "    \"각 현상에 대해 간단한 설명을 포함해주세요.\"\n",
    ")\n",
    "\n",
    "# OpenAI 모델 초기화\n",
    "#model = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.5)\n",
    "model = ChatOpenAI(\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API 엔드포인트\n",
    "    model=\"meta-llama/llama-4-scout-17b-16e-instruct\",\n",
    "    temperature=0.5\n",
    ")\n",
    "\n",
    "# 특정 계절의 현상 질의\n",
    "chain = (\n",
    "    {\"season\": lambda x: season}\n",
    "    | prompt\n",
    "    | model\n",
    "    | StrOutputParser()\n",
    ")\n",
    "result = chain.invoke({})\n",
    "\n",
    "\n",
    "# 결과 출력\n",
    "print(f\"🔹 프롬프트: {prompt}\")\n",
    "print(f\"🔹 모델 응답: {season}에 발생하는 자연 현상: \\n {result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41c26e19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2cd72ced",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=[] input_types={} partial_variables={'info': '1달러 = 1365.14원'} template='현재 {info} 기준으로 환율 정보를 알려드립니다. 현재 환율을 기준으로 한국 경제 미치는 영향 및 향후에 환율 분석을 제공해주세요. '\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# 실시간 환율을 가져오는 함수\n",
    "def get_exchange_rate():\n",
    "    response = requests.get(\"https://api.exchangerate-api.com/v4/latest/USD\") # 환율 정보\n",
    "    data = response.json()\n",
    "    return f\"1달러 = {data['rates']['KRW']}원\"\n",
    "\n",
    "# {info} 변수에 API에서 받은 환율 정보를 동적으로 반영\n",
    "prompt = PromptTemplate(\n",
    "    template=\"현재 {info} 기준으로 환율 정보를 알려드립니다. 현재 환율을 기준으로 한국 경제 미치는 영향 및 향후에 환율 분석을 제공해주세요. \",\n",
    "    input_variables=[],  # 사용자 입력 없음\n",
    "    partial_variables={\"info\": get_exchange_rate()}  # API에서 가져온 데이터 자동 반영\n",
    ")\n",
    "\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cbc6f9e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔹 프롬프트: 현재 1달러 = 1365.14원 기준으로 환율 정보를 알려드립니다. 현재 환율을 기준으로 한국 경제 미치는 영향 및 향후에 환율 분석을 제공해주세요. \n",
      "🔹 모델 응답: ## 현재 환율 정보\n",
      "\n",
      "*   현재 1달러 = 1365.14원 (기준일자: 2023.12.29.) \n",
      "\n",
      "## 한국 경제에 미치는 영향\n",
      "\n",
      "*   **수출 증가**: 약한 원화 가치는 한국의 수출에 긍정적인 영향을 미칩니다. 원화 약세는 한국의 수출 상품 가격을 해외 시장에서 더 경쟁력 있게 만들어 수출 증가로 이어질 수 있습니다. 이는 무역 수지 개선과 경제 성장에 기여할 수 있습니다.\n",
      "*   **수입 비용 증가**: 원화 약세는 수입 물가를 상승시켜 국내 물가 상승 압력을 가중시킬 수 있습니다. 이는 소비자들의 구매력을 감소시키고, 특히 원유, 곡물 등 필수 수입품목의 가격 상승으로 이어져 인플레이션을 심화시킬 수 있습니다.\n",
      "*   **외국인 투자 감소**: 원화 약세는 외국인 투자자들에게 한국 시장에 대한 부정적인 신호로 작용할 수 있습니다. 이는 외국인 직접 투자 감소로 이어져, 장기적인 경제 성장에 부정적인 영향을 미칠 수 있습니다.\n",
      "\n",
      "## 향후 환율 전망\n",
      "\n",
      "*   **글로벌 경제 상황**: 글로벌 경제 상황, 특히 미국의 경제 상황과 통화 정책이 원달러 환율에 큰 영향을 미칠 것입니다. 미국 경제가 강한 회복세를 보이면, 달러화 강세가 지속될 수 있습니다. \n",
      "*   **한국 경제 상황**: 한국의 경제 성장률, 물가 상승률, 무역 수지 등도 환율에 영향을 미칠 것입니다. \n",
      "*   **금리 인상**: 미국 연방준비제도(Fed)가 금리를 인상할 경우, 달러화 강세가 지속될 수 있습니다. \n",
      "*   **원화 가치**: 원화 가치가 상승할 경우, 환율이 하락할 수 있습니다.\n",
      "\n",
      "향후 환율 전망은 불확실하며, 다양한 요인들이 영향을 미칠 것입니다. 경제 전문가들의 분석과 예측을 참고하여, 환율 변동에 대비하는 것이 중요합니다.\n"
     ]
    }
   ],
   "source": [
    "# # LLM 모델 설정 (GPT-4o-mini 사용)\n",
    "# model = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.0)\n",
    "model = ChatOpenAI(\n",
    "    #api_key=OPENAI_API_KEY,\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API 엔드포인트\n",
    "    model=\"meta-llama/llama-4-scout-17b-16e-instruct\",\n",
    "    temperature=0.5 # 이번엔 0.5\n",
    ")\n",
    "\n",
    "# 모델에 프롬프트 전달 및 응답 받기\n",
    "response = model.invoke(prompt.format())\n",
    "\n",
    "# 결과 출력\n",
    "print(\"🔹 프롬프트:\", prompt.format())\n",
    "print(\"🔹 모델 응답:\", response.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-basic-kGdHTiMZ-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
